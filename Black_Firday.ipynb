{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('Atrain.csv')\n",
    "test=pd.read_csv('Atest.csv')\n",
    "submission=pd.read_csv('/home/saikantareddy/Downloads/Sample_Submission_Tm9Lura.csv')\n",
    "#x=['User_ID','Product_ID','Gender','Age','Occupation','City_Category','Stay_In_Current_City_Years','Marital_Status','Product_Category_1','Product_Category_2','Product_Category_3','Purchase']\n",
    "#for  i in x:\n",
    "#    for dataset in combine:\n",
    "#        try:\n",
    "            #print(dataset[i].value_counts())\n",
    "#            dataset[i].fillna(dataset[i].median(),inplace=True)\n",
    "#            #dataset[i].astype('int')\n",
    "#        except:\n",
    "#            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>User_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-17</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>8370.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-17</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>15200.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-17</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-17</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55+</td>\n",
       "      <td>C</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>7969.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>1000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age City_Category Gender  Marital_Status  Occupation  Product_Category_1  \\\n",
       "0  0-17             A      F               0          10                   3   \n",
       "1  0-17             A      F               0          10                   1   \n",
       "2  0-17             A      F               0          10                  12   \n",
       "3  0-17             A      F               0          10                  12   \n",
       "4   55+             C      M               0          16                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3 Product_ID  Purchase  \\\n",
       "0                 NaN                 NaN  P00069042    8370.0   \n",
       "1                 6.0                14.0  P00248942   15200.0   \n",
       "2                 NaN                 NaN  P00087842    1422.0   \n",
       "3                14.0                 NaN  P00085442    1057.0   \n",
       "4                 NaN                 NaN  P00285442    7969.0   \n",
       "\n",
       "  Stay_In_Current_City_Years  User_ID  \n",
       "0                          2  1000001  \n",
       "1                          2  1000001  \n",
       "2                          2  1000001  \n",
       "3                          2  1000001  \n",
       "4                         4+  1000002  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine=[train,test]\n",
    "input=pd.concat(combine)\n",
    "input.shape\n",
    "input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 783667 entries, 0 to 233598\n",
      "Data columns (total 12 columns):\n",
      "Age                           783667 non-null object\n",
      "City_Category                 783667 non-null object\n",
      "Gender                        783667 non-null object\n",
      "Marital_Status                783667 non-null int64\n",
      "Occupation                    783667 non-null int64\n",
      "Product_Category_1            783667 non-null int64\n",
      "Product_Category_2            537685 non-null float64\n",
      "Product_Category_3            237858 non-null float64\n",
      "Product_ID                    783667 non-null object\n",
      "Purchase                      550068 non-null float64\n",
      "Stay_In_Current_City_Years    783667 non-null object\n",
      "User_ID                       783667 non-null int64\n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 77.7+ MB\n"
     ]
    }
   ],
   "source": [
    "input.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=input['Purchase']\n",
    "target=np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.drop(['Purchase'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                           object\n",
       "City_Category                 object\n",
       "Gender                        object\n",
       "Marital_Status                object\n",
       "Occupation                    object\n",
       "Product_Category_1            object\n",
       "Product_Category_2            object\n",
       "Product_Category_3            object\n",
       "Product_ID                    object\n",
       "Stay_In_Current_City_Years    object\n",
       "User_ID                       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=input.applymap(str)\n",
    "input.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pd=input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=np.array(input)\n",
    "for i in range(input.shape[1]):\n",
    "    lbl=preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(input[:,i]))\n",
    "    input[:,i]=lbl.transform(input[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=input.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275034,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_stage_rows=np.random.randint(train.shape[0],size=np.int(train.shape[0]/2))\n",
    "first_stage_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np=input[:train.shape[0],:]\n",
    "target_np=target[:train.shape[0]]\n",
    "train_fs=train_np[first_stage_rows,:]\n",
    "target_fs=target_np[first_stage_rows]\n",
    "train_ss=train_np[-first_stage_rows,:]\n",
    "target_ss=target_np[-first_stage_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain=xgb.DMatrix(train_fs,label=target_fs)\n",
    "watchlist=[(xgtrain,'train')]\n",
    "params={}\n",
    "params['min_child_weight']=10\n",
    "params['subsample']=0.7\n",
    "params['colsample_bytree']=0.7\n",
    "params['scale_pos_weight']=0.8\n",
    "params['max_depth']=6\n",
    "params['nthread']=6\n",
    "params['objective']='reg:linear'\n",
    "params['eta']=0.1\n",
    "params['base_score']=1800\n",
    "params['eval_metric']='rmse'\n",
    "params['seed']=0\n",
    "\n",
    "plst=list(params.items())\n",
    "num_rounds=3000\n",
    "model_1=xgb.train(plst,xgtrain,num_rounds)\n",
    "\n",
    "params = {}\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 8\n",
    "params[\"nthread\"] = 6\n",
    "#params[\"gamma\"] = 1\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"base_score\"] = 1800\n",
    "params[\"eval_metric\"] = \"rmse\"\n",
    "params[\"seed\"] = 0\n",
    "\n",
    "plst = list(params.items())\n",
    "num_rounds = 1420\n",
    "\n",
    "model_2 = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "# Model 3: 10/1200\n",
    "\n",
    "params = {}\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 10\n",
    "params[\"nthread\"] = 6\n",
    "#params[\"gamma\"] = 1\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"base_score\"] = 1800\n",
    "params[\"eval_metric\"] = \"rmse\"\n",
    "params[\"seed\"] = 0\n",
    "\n",
    "plst = list(params.items())\n",
    "num_rounds = 1200\n",
    "\n",
    "model_3 = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "# Model 4: 12/800\n",
    "\n",
    "params = {}\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 12\n",
    "params[\"nthread\"] = 6\n",
    "#params[\"gamma\"] = 1\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"base_score\"] = 1800\n",
    "params[\"eval_metric\"] = \"rmse\"\n",
    "params[\"seed\"] = 0\n",
    "\n",
    "plst = list(params.items())\n",
    "num_rounds = 800\n",
    "\n",
    "model_4 = xgb.train(plst, xgtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done 1450 out of 1450 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=6)]: Done 3000 out of 3000 | elapsed:  7.5min finished\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done 800 out of 800 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=12,\n",
       "          max_features='auto', max_leaf_nodes=None,\n",
       "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "          min_samples_leaf=10, min_samples_split=10,\n",
       "          min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=6,\n",
       "          oob_score=True, random_state=123, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = ExtraTreesRegressor(n_estimators=1450, \n",
    "                              max_depth=8,\n",
    "                              min_samples_split=10, \n",
    "                              min_samples_leaf=10, \n",
    "                              oob_score=True, \n",
    "                              n_jobs=6, \n",
    "                              random_state=123, \n",
    "                              verbose=1, \n",
    "                              bootstrap=True)\n",
    "model_5.fit(train_fs, target_fs)\n",
    "\n",
    "# Model 6: 6/3000\n",
    "\n",
    "model_6 = ExtraTreesRegressor(n_estimators=3000, \n",
    "                              max_depth=6,\n",
    "                              min_samples_split=10, \n",
    "                              min_samples_leaf=10, \n",
    "                              oob_score=True, \n",
    "                              n_jobs=6, \n",
    "                              random_state=123, \n",
    "                              verbose=1, \n",
    "                              bootstrap=True)\n",
    "model_6.fit(train_fs, target_fs)\n",
    "\n",
    "# Model 7: 12/800\n",
    "\n",
    "model_7 = ExtraTreesRegressor(n_estimators=800, \n",
    "                              max_depth=12,\n",
    "                              min_samples_split=10, \n",
    "                              min_samples_leaf=10, \n",
    "                              oob_score=True, \n",
    "                              n_jobs=6, \n",
    "                              random_state=123, \n",
    "                              verbose=1, \n",
    "                              bootstrap=True)\n",
    "model_7.fit(train_fs, target_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=12,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=10, min_samples_split=10,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=6,\n",
       "           oob_score=True, random_state=123, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8 = RandomForestRegressor(n_estimators=3000, max_depth=6, oob_score=True, n_jobs=6, random_state=123, min_samples_split=10, min_samples_leaf=10)\n",
    "model_8.fit(train_fs, target_fs)\n",
    "\n",
    "# Model 9: 8/1500\n",
    "model_9 = RandomForestRegressor(n_estimators=1500, max_depth=8, oob_score=True, n_jobs=6, random_state=123, min_samples_split=10, min_samples_leaf=10)\n",
    "model_9.fit(train_fs, target_fs)\n",
    "\n",
    "# Model 10: 12/800\n",
    "model_10 = RandomForestRegressor(n_estimators=800, max_depth=12, oob_score=True, n_jobs=6, random_state=123, min_samples_split=10, min_samples_leaf=10)\n",
    "model_10.fit(train_fs, target_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=6)]: Done 1450 out of 1450 | elapsed:    5.5s finished\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=6)]: Done 3000 out of 3000 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=6)]: Done 800 out of 800 | elapsed:    5.1s finished\n"
     ]
    }
   ],
   "source": [
    "model_1_predict = model_1.predict(xgb.DMatrix(train_ss))\n",
    "model_2_predict = model_2.predict(xgb.DMatrix(train_ss))\n",
    "model_3_predict = model_3.predict(xgb.DMatrix(train_ss))\n",
    "model_4_predict = model_4.predict(xgb.DMatrix(train_ss))\n",
    "model_5_predict = model_5.predict(train_ss)\n",
    "model_6_predict = model_6.predict(train_ss)\n",
    "model_7_predict = model_7.predict(train_ss)\n",
    "model_8_predict = model_8.predict(train_ss)\n",
    "model_9_predict = model_9.predict(train_ss)\n",
    "model_10_predict = model_10.predict(train_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ss_w_meta = np.concatenate((train_ss, np.vstack((model_1_predict, model_2_predict, model_3_predict, \n",
    "                                                       model_4_predict, model_5_predict,\n",
    "              model_6_predict, model_7_predict, model_8_predict, model_9_predict, model_10_predict)).T), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(train_ss_w_meta.shape[0], n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 8\n",
    "params[\"nthread\"] = 6\n",
    "#params[\"gamma\"] = 1\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"base_score\"] = 1800\n",
    "params[\"eval_metric\"] = \"rmse\"\n",
    "params[\"seed\"] = 0\n",
    "\n",
    "plst = list(params.items())\n",
    "num_rounds = 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9025.704073015733\n",
      "9000.82897924893\n",
      "9019.842168511079\n",
      "8984.081057545223\n",
      "9035.337397844334\n"
     ]
    }
   ],
   "source": [
    "for train_index, validation_index in kfolds:\n",
    "    \n",
    "    train_X, validation_X = train_ss_w_meta[train_index, :], train_ss_w_meta[validation_index, :]\n",
    "    train_y, validation_y = target_ss[train_index], target_ss[validation_index]\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "    watchlist = [(xgtrain, 'train')]\n",
    "    model_cv_xgboost = xgb.train(plst, xgtrain, num_rounds)\n",
    "    model_cv_predict = model_cv_xgboost.predict(xgb.DMatrix(validation_X))\n",
    "    print(np.sqrt(mean_squared_error(validation_y, model_cv_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(train_ss_w_meta, label=target_ss)\n",
    "watchlist = [(xgtrain, 'train')]\n",
    "model_ss_xgboost = xgb.train(plst, xgtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=6)]: Done 1450 out of 1450 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=6)]: Done 3000 out of 3000 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=6)]: Done 800 out of 800 | elapsed:    4.5s finished\n"
     ]
    }
   ],
   "source": [
    "model_1_predict = model_1.predict(xgb.DMatrix(input[train.shape[0]:, :]))\n",
    "model_2_predict = model_2.predict(xgb.DMatrix(input[train.shape[0]:, :]))\n",
    "model_3_predict = model_3.predict(xgb.DMatrix(input[train.shape[0]:, :]))\n",
    "model_4_predict = model_4.predict(xgb.DMatrix(input[train.shape[0]:, :]))\n",
    "model_5_predict = model_5.predict(input[train.shape[0]:, :])\n",
    "model_6_predict = model_6.predict(input[train.shape[0]:, :])\n",
    "model_7_predict = model_7.predict(input[train.shape[0]:, :])\n",
    "model_8_predict = model_8.predict(input[train.shape[0]:, :])\n",
    "model_9_predict = model_9.predict(input[train.shape[0]:, :])\n",
    "model_10_predict = model_10.predict(input[train.shape[0]:, :])\n",
    "\n",
    "test_ss_w_meta = np.concatenate((input[train.shape[0]:, :], np.vstack((model_1_predict, model_2_predict, model_3_predict, \n",
    "                                                       model_4_predict, model_5_predict,\n",
    "              model_6_predict, model_7_predict, model_8_predict, model_9_predict, model_10_predict)).T), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ss_predict = model_ss_xgboost.predict(xgb.DMatrix(test_ss_w_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800.0, 1800.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(model_ss_predict), np.min(model_ss_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.Purchase = model_ss_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submit_23.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
